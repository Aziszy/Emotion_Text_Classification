{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nmZPji5UghG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbfy6k0TUghJ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('emotions.txt',names=['sentence','emotions'], sep=';')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBUc78GU3yPP"
      },
      "outputs": [],
      "source": [
        "label_count = df['emotions'].value_counts()\n",
        "\n",
        "for i in range(0,6):\n",
        "    print(f'Class {i} : {label_count[i]}')\n",
        "\n",
        "label_count.plot(kind='bar', title='Count label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z0R8ybp3yPQ"
      },
      "outputs": [],
      "source": [
        "df_class_0 = df[df['emotions'] == 'joy']\n",
        "df_class_1 = df[df['emotions'] == 'sadness']\n",
        "df_class_2 = df[df['emotions'] == 'anger']\n",
        "df_class_3 = df[df['emotions'] == 'fear']\n",
        "df_class_4 = df[df['emotions'] == 'love']\n",
        "df_class_5 = df[df['emotions'] == 'surprise']\n",
        "\n",
        "df_class_1_over = df_class_1.sample(label_count[0], replace=True)\n",
        "df_class_2_over = df_class_2.sample(label_count[0], replace=True)\n",
        "df_class_3_over = df_class_3.sample(label_count[0], replace=True)\n",
        "df_class_4_over = df_class_4.sample(label_count[0], replace=True)\n",
        "df_class_5_over = df_class_5.sample(label_count[0], replace=True)\n",
        "\n",
        "df_over = pd.concat([\n",
        "                    df_class_0,\n",
        "                    df_class_1_over,\n",
        "                    df_class_2_over,\n",
        "                    df_class_3_over,\n",
        "                    df_class_4_over,\n",
        "                    df_class_5_over],axis=0)\n",
        "\n",
        "print('Random Over Sampling')\n",
        "print(df_over['emotions'].value_counts())\n",
        "df_over['emotions'].value_counts().plot(kind='bar', title='Count label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2U7DG7_UghK"
      },
      "outputs": [],
      "source": [
        "label = pd.get_dummies(df_over['emotions'])\n",
        "datasets = pd.concat([df_over, label], axis=1)\n",
        "datasets = datasets.drop(columns='emotions')\n",
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7B-qukkUghL"
      },
      "outputs": [],
      "source": [
        "label_name = [\n",
        "    'anger',\n",
        "    'fear',\n",
        "    'joy',\n",
        "    'love',\n",
        "    'sadness',\n",
        "    'surprise',\n",
        "    ]\n",
        "\n",
        "sentence = datasets['sentence'].values\n",
        "label = datasets[label_name].values\n",
        "\n",
        "train_tweet, test_tweet, train_label, test_label = train_test_split(\n",
        "    sentence, \n",
        "    label, \n",
        "    test_size=0.2,\n",
        "    random_state=1,\n",
        "    )\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token='x')\n",
        "tokenizer.fit_on_texts(train_tweet)\n",
        "tokenizer.fit_on_texts(test_tweet)\n",
        "\n",
        "train_sequence = tokenizer.texts_to_sequences(train_tweet)\n",
        "test_sequence = tokenizer.texts_to_sequences(test_tweet)\n",
        "\n",
        "train_padded = pad_sequences(train_sequence)\n",
        "test_padded = pad_sequences(test_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEh-X7ePUghM"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (logs.get('accuracy')>0.95):\n",
        "            self.model.stop_training = True;\n",
        "            print('\\nAkurasi telah melewati 95%')\n",
        "\n",
        "callbacks = myCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4tCuYKdUghM"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    layers.Embedding(input_dim=5000, output_dim=16),\n",
        "    layers.LSTM(64),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(6, activation='softmax'),\n",
        "    ])\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        "    )\n",
        "hist = model.fit(\n",
        "    train_padded,\n",
        "    train_label, \n",
        "    epochs=30,\n",
        "    validation_data=(test_padded, test_label),\n",
        "    verbose=2,\n",
        "    callbacks=[callbacks],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2AlMHLOUghN"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SubmissionNLP.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "25f0aba0b9a2d213117a240daa75dbf8ce80c7f9a754a399687148d3372654e0"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}